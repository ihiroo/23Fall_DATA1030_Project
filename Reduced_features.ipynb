{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d8228a-1e4c-4e71-aab2-2a401bfd75df",
   "metadata": {},
   "source": [
    "### Import Data & Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28d0bb-eb88-48f4-8f6f-93cf6188224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634cea0-bf68-41b8-93c8-494b29311f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown and 999 should be treated as missing values\n",
    "df = pd.read_csv('bank-additional-full.csv', sep = ';', na_values = ['unknown', 999])\n",
    "df = df.drop(columns = ['duration']) # drop future information\n",
    "\n",
    "# deal with campaign\n",
    "# remove future information\n",
    "df['ncalls'] = df['campaign'] - 1\n",
    "df = df.drop(columns = ['campaign'])\n",
    "print(df.shape)\n",
    "\n",
    "X = df.drop(columns = 'y')\n",
    "y = df['y'] # this is a classification problem\n",
    "y = y.replace({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f5111-8b31-4b9a-8b76-dfc328b904e7",
   "metadata": {},
   "source": [
    "### Define Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49b884-7841-4afe-abea-b66a85d65b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ftrs = ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "\n",
    "ordinal_ftrs = ['education', 'month', 'day_of_week']\n",
    "ordinal_cats = [['NA', 'illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', \n",
    "                 'professional.course', 'university.degree'],\n",
    "                ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
    "                ['mon', 'tue', 'wed', 'thu', 'fri']]\n",
    "\n",
    "num_ftrs = ['age', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', \n",
    "            'euribor3m', 'nr.employed', 'ncalls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a47d91-0dca-4421-8c55-1ae06489f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'constant', fill_value = 'missing')), \n",
    "    ('onehot', OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# ordinal encoder\n",
    "ordinal_transformer = Pipeline(steps = [\n",
    "    ('imputer2', SimpleImputer(strategy = 'constant', fill_value = 'NA')),\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps = [\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47193654-beb1-4f6b-9664-88126b49167e",
   "metadata": {},
   "source": [
    "# Maybe try 5 different random states?\n",
    "# Maybe try 5 folds?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd04e14-adee-4669-9d29-8b6b29c01566",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c12746-ac87-4f8d-904a-084fb85a7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MLpipe_kfold_reduced_features_rf(X, y, random_states, preprocessor, param_grid, n_splits = 3):\n",
    "    ap_scores_random_state = {}\n",
    "    mean_ap_scores = [] # in each fold\n",
    "    for random_state in random_states:\n",
    "        ap_scores_test = [] # ap score for each test fold\n",
    "        kf = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state = random_state)\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state)\n",
    "        for train_index, val_index in kf.split(X_other, y_other):\n",
    "            X_train = X_other.iloc[train_index]\n",
    "            y_train = y_other.iloc[train_index]\n",
    "            X_val = X_other.iloc[val_index]\n",
    "            y_val = y_other.iloc[val_index]\n",
    "\n",
    "            # preprocessing\n",
    "            X_prep = preprocessor.fit_transform(X_train)\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "            df_train = pd.DataFrame(data = X_prep, columns = feature_names)\n",
    "            df_val = pd.DataFrame(data = preprocessor.transform(X_val), columns = feature_names)\n",
    "            df_test = pd.DataFrame(data = preprocessor.transform(X_test), columns = feature_names)\n",
    "\n",
    "            mask = df_test.isnull()\n",
    "            unique_rows = np.array(np.unique(mask, axis = 0))\n",
    "            all_y_test_pred = pd.DataFrame()\n",
    "            #print('There are', len(unique_rows), 'unique missing value patterns')\n",
    "            for i in range(len(unique_rows)):\n",
    "                #print('Working on unique pattern', i)\n",
    "                sub_X_test = pd.DataFrame()\n",
    "                sub_y_test = pd.Series(dtype = float)\n",
    "                for j in range(len(mask)):\n",
    "                    row_mask = np.array(mask.iloc[j])\n",
    "                    if np.array_equal(row_mask, unique_rows[i]):\n",
    "                        sub_X_test = pd.concat([sub_X_test, df_test.iloc[[j]]])\n",
    "                        sub_y_test = pd.concat([sub_y_test, y_test.iloc[[j]]])\n",
    "                sub_X_test = sub_X_test[df_test.columns[~unique_rows[i]]]\n",
    "               \n",
    "                sub_X_train = pd.DataFrame()\n",
    "                sub_y_train = pd.DataFrame()\n",
    "                sub_X_val = pd.DataFrame()\n",
    "                sub_y_val = pd.DataFrame()\n",
    "                sub_X_train = df_train[df_train.columns[~unique_rows[i]]]\n",
    "                sub_X_val = df_val[df_val.columns[~unique_rows[i]]]\n",
    "                sub_X_train = sub_X_train.dropna()\n",
    "                sub_X_val = sub_X_val.dropna()   \n",
    "                sub_y_train = y_train.iloc[sub_X_train.index]\n",
    "                sub_y_val = y_val.iloc[sub_X_val.index]\n",
    "\n",
    "                # run ML algo\n",
    "                # change to 1-D array\n",
    "                sub_y_train_array = sub_y_train.values.ravel()\n",
    "                sub_y_val_array = sub_y_val.values.ravel()\n",
    "                sub_y_test_array = sub_y_test.values.ravel()\n",
    "                \n",
    "                ML_algo = RandomForestClassifier(random_state = 42 * random_state, n_jobs = -1)\n",
    "                param_grid = param_grid\n",
    "                pg = ParameterGrid(param_grid)\n",
    "                best_ap = 0\n",
    "                best_model = None\n",
    "                #train_scores = np.zeros(len(pg))\n",
    "                #val_scores = np.zeros(len(pg))\n",
    "                #models = []\n",
    "                \n",
    "                for p in range(len(pg)):\n",
    "                    params = pg[p]\n",
    "                    #print('   ', params)\n",
    "                    ML_algo.set_params(**params)\n",
    "                    ML_algo.fit(sub_X_train, sub_y_train_array)\n",
    "                    pred_prob_val = ML_algo.predict_proba(sub_X_val)[:, 1]\n",
    "                    ap = average_precision_score(sub_y_val, pred_prob_val)\n",
    "\n",
    "                    if ap > best_ap:\n",
    "                        best_ap = ap\n",
    "                        best_model = ML_algo\n",
    "                    pred_prob_test = best_model.predict_proba(sub_X_test)[:, 1]\n",
    "                    test_ap = average_precision_score(sub_y_test, pred_prob_test)\n",
    "                    ap_scores_test.append(test_ap)\n",
    "\n",
    "                    sub_y_test_pred = best_model.predict(sub_X_test)\n",
    "                    models.append(ML_algo) # save the model\n",
    "                    sub_y_train_pred = ML_algo.predict(sub_X_train)\n",
    "                    train_scores[p] = accuracy_score(sub_y_train_array, sub_y_train_pred)\n",
    "                    sub_y_val_pred = ML_algo.predict(sub_X_val)\n",
    "                    val_scores[p] = accuracy_score(sub_y_val_array, sub_y_val_pred)\n",
    "                    #print('   ', train_scores[p], val_scores[p])\n",
    "                best_params = np.array(pg)[val_scores == np.max(val_scores)]\n",
    "                #print('Best model parameters:\\n', best_params)\n",
    "                #print('Corresponding validation score:', np.max(val_scores))\n",
    "               \n",
    "                # plot train_scores and val_scores\n",
    "                # param_grid is ok\n",
    "                #plt.figure(figsize = (5, 3))\n",
    "                #plt.plot(train_scores, label = 'Training Accuracy')\n",
    "                #plt.plot(val_scores, label = 'Validation Accuracy')\n",
    "                #plt.legend()\n",
    "                #plt.show()\n",
    "                \n",
    "                ML_algo.set_params(**best_params[0])\n",
    "                ML_algo.fit(sub_X_train, sub_y_train_array)\n",
    "                sub_y_test_pred = ML_algo.predict(sub_X_test)\n",
    "                sub_y_test_pred = pd.DataFrame(sub_y_test_pred, index = sub_y_test.index, \n",
    "                                               columns = ['sub_y_test_pred']) # convert into data frame\n",
    "                all_y_test_pred = pd.concat([all_y_test_pred, sub_y_test_pred])\n",
    "                    \n",
    "            all_y_test_pred = all_y_test_pred.sort_index()\n",
    "            y_test = y_test.sort_index()\n",
    "\n",
    "            # test recall in one-fold\n",
    "            # have n_splits scores for each random_state\n",
    "            recall_test = accuracy_score(y_test, all_y_test_pred) # total accuracy\n",
    "            recall_scores_test.append(recall_test)\n",
    "            cm = confusion_matrix(y_test, all_y_test_pred)\n",
    "            disp = ConfusionMatrixDisplay(cm, display_labels = ['Class 0', 'Class 1'])\n",
    "            fig, ax = plt.subplots(figsize = (5, 3))\n",
    "            disp.plot(ax = ax)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        # mean test recall for this random_state\n",
    "        mean_recall = np.mean(recall_scores_test)\n",
    "        mean_recall_scores.append(mean_recall)\n",
    "        recall_scores_random_state[random_state] = mean_recall\n",
    "        #print(f'Mean test recall for random state {random_state}: {mean_recall}\\n')\n",
    "    # mean & std recall for all random states\n",
    "    overall_mean_ap = np.mean(mean_recall_scores)\n",
    "    overall_std_ap = np.std(mean_recall_scores)\n",
    "    #print(f'Overall mean test recall across all random states: {overall_mean_recall}')\n",
    "    #print(f'Overall std test recall across all random states: {overall_std_recall}\\n')\n",
    "    \n",
    "    return overall_mean_ap, overall_std_ap, ap_scores_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb2af9-d387-4dac-971f-8c8643b043a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ParameterGrid\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def MLpipe_kfold_reduced_features_rf(X, y, random_states, preprocessor, param_grid, n_splits=3):\n",
    "    ap_scores_random_state = {}\n",
    "    mean_ap_scores = []  # Average Precision scores for each random state\n",
    "\n",
    "    for random_state in random_states:\n",
    "        ap_scores_test = []  # Store AP scores for each test fold\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "        for train_index, val_index in kf.split(X_other, y_other):\n",
    "            X_train, y_train = X_other.iloc[train_index], y_other.iloc[train_index]\n",
    "            X_val, y_val = X_other.iloc[val_index], y_other.iloc[val_index]\n",
    "\n",
    "            # Preprocessing\n",
    "            X_train_prep = preprocessor.fit_transform(X_train)\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "            df_train = pd.DataFrame(data=X_train_prep, columns=feature_names)\n",
    "            df_val = pd.DataFrame(data=preprocessor.transform(X_val), columns=feature_names)\n",
    "            df_test = pd.DataFrame(data=preprocessor.transform(X_test), columns=feature_names)\n",
    "\n",
    "            mask = df_test.isnull()\n",
    "            unique_rows = np.array(np.unique(mask, axis=0))\n",
    "            all_y_test_pred = pd.DataFrame()\n",
    "            \n",
    "            for i in range(len(unique_rows)):\n",
    "                sub_X_test, sub_y_test = pd.DataFrame(), pd.Series(dtype=float)\n",
    "                for j in range(len(mask)):\n",
    "                    row_mask = np.array(mask.iloc[j])\n",
    "                    if np.array_equal(row_mask, unique_rows[i]):\n",
    "                        sub_X_test = pd.concat([sub_X_test, df_test.iloc[[j]]])\n",
    "                        sub_y_test = pd.concat([sub_y_test, y_test.iloc[[j]]])\n",
    "                sub_X_test = sub_X_test[df_test.columns[~unique_rows[i]]]\n",
    "               \n",
    "                sub_X_train = df_train[df_train.columns[~unique_rows[i]]].dropna()\n",
    "                sub_X_val = df_val[df_val.columns[~unique_rows[i]]].dropna()\n",
    "                sub_y_train, sub_y_val = y_train.iloc[sub_X_train.index], y_val.iloc[sub_X_val.index]\n",
    "\n",
    "                # Training the model\n",
    "                ML_algo = RandomForestClassifier(random_state=42 * random_state, n_jobs=-1)\n",
    "                pg = ParameterGrid(param_grid)\n",
    "                best_ap = 0\n",
    "                best_model = None\n",
    "\n",
    "                for params in pg:\n",
    "                    ML_algo.set_params(**params)\n",
    "                    ML_algo.fit(sub_X_train, sub_y_train)\n",
    "\n",
    "                    # Predict probabilities and calculate AP\n",
    "                    pred_prob_val = ML_algo.predict_proba(sub_X_val)[:, 1]\n",
    "                    ap = average_precision_score(sub_y_val, pred_prob_val)\n",
    "\n",
    "                    if ap > best_ap:\n",
    "                        best_ap = ap\n",
    "                        best_model = ML_algo\n",
    "\n",
    "                # Predict on test set and calculate AP\n",
    "                pred_prob_test = best_model.predict_proba(sub_X_test)[:, 1]\n",
    "                test_ap = average_precision_score(sub_y_test, pred_prob_test)\n",
    "                ap_scores_test.append(test_ap)\n",
    "\n",
    "                # Optional: Display confusion matrix\n",
    "                sub_y_test_pred = best_model.predict(sub_X_test)\n",
    "                cm = confusion_matrix(sub_y_test, sub_y_test_pred)\n",
    "                disp = ConfusionMatrixDisplay(cm, display_labels=['Class 0', 'Class 1'])\n",
    "                disp.plot()\n",
    "        \n",
    "        # Average AP score for this random state\n",
    "        mean_ap = np.mean(ap_scores_test)\n",
    "        mean_ap_scores.append(mean_ap)\n",
    "        ap_scores_random_state[random_state] = mean_ap\n",
    "\n",
    "    # Overall mean and std AP across all random states\n",
    "    overall_mean_ap = np.mean(mean_ap_scores)\n",
    "    overall_std_ap = np.std(mean_ap_scores)\n",
    "    \n",
    "    return overall_mean_ap, overall_std_ap, ap_scores_random_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09c185-d960-4e30-80e8-9659cfd9b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [42, 123]\n",
    "param_grid = {\n",
    "    'max_depth': [1, 3, 9, 12, None],\n",
    "    'max_features': [0.15, 0.5, 0.75, 1, None]\n",
    "}\n",
    "\n",
    "mean_recall_rf, std_recall_rf, recall_random_state_rf = MLpipe_kfold_reduced_features_rf(X, y, random_states, \n",
    "                                                                                               preprocessor, param_grid, \n",
    "                                                                                               n_splits = 3)\n",
    "print('Random forest mean recall:', mean_recall_rf)\n",
    "print('Random forest std recall:', std_recall_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e8203-069c-44d1-a7d1-2fb89c82e0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "513cd106-023e-4bdc-806c-91ccec41baa5",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3d64d-5ab9-4e4a-9a0b-4e44c18f1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def MLpipe_kfold_reduced_features_knn(X, y, random_states, preprocessor, param_grid, n_splits = 3):\n",
    "    accuracy_scores_random_state = {}\n",
    "    accuracy_scores_test = []\n",
    "    mean_accuracy_scores = [] # in each fold\n",
    "    for random_state in random_states:\n",
    "        kf = KFold(n_splits = n_splits, shuffle = True, random_state = random_state)\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state)\n",
    "        for train_index, val_index in kf.split(X_other, y_other):\n",
    "            X_train = X_other.iloc[train_index]\n",
    "            y_train = y_other.iloc[train_index]\n",
    "            X_val = X_other.iloc[val_index]\n",
    "            y_val = y_other.iloc[val_index]\n",
    "\n",
    "            # preprocessing\n",
    "            X_prep = preprocessor.fit_transform(X_train)\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "            df_train = pd.DataFrame(data = X_prep, columns = feature_names)\n",
    "            df_val = pd.DataFrame(data = preprocessor.transform(X_val), columns = feature_names)\n",
    "            df_test = pd.DataFrame(data = preprocessor.transform(X_test), columns = feature_names)\n",
    "\n",
    "            mask = df_test.isnull()\n",
    "            unique_rows = np.array(np.unique(mask, axis = 0))\n",
    "            all_y_test_pred = pd.DataFrame()\n",
    "            #print('There are', len(unique_rows), 'unique missing value patterns')\n",
    "            for i in range(len(unique_rows)):\n",
    "                #print('Working on unique pattern', i)\n",
    "                sub_X_test = pd.DataFrame()\n",
    "                sub_y_test = pd.Series(dtype = float)\n",
    "                for j in range(len(mask)):\n",
    "                    row_mask = np.array(mask.iloc[j])\n",
    "                    if np.array_equal(row_mask, unique_rows[i]):\n",
    "                        sub_X_test = pd.concat([sub_X_test, df_test.iloc[[j]]])\n",
    "                        sub_y_test = pd.concat([sub_y_test, y_test.iloc[[j]]])\n",
    "                sub_X_test = sub_X_test[df_test.columns[~unique_rows[i]]]\n",
    "               \n",
    "                sub_X_train = pd.DataFrame()\n",
    "                sub_y_train = pd.DataFrame()\n",
    "                sub_X_val = pd.DataFrame()\n",
    "                sub_y_val = pd.DataFrame()\n",
    "                sub_X_train = df_train[df_train.columns[~unique_rows[i]]]\n",
    "                sub_X_val = df_val[df_val.columns[~unique_rows[i]]]\n",
    "                sub_X_train = sub_X_train.dropna()\n",
    "                sub_X_val = sub_X_val.dropna()   \n",
    "                sub_y_train = y_train.iloc[sub_X_train.index]\n",
    "                sub_y_val = y_val.iloc[sub_X_val.index]\n",
    "\n",
    "                # run ML algo\n",
    "                # change to 1-D array\n",
    "                sub_y_train_array = sub_y_train.values.ravel()\n",
    "                sub_y_val_array = sub_y_val.values.ravel()\n",
    "                sub_y_test_array = sub_y_test.values.ravel()\n",
    "                \n",
    "                ML_algo = KNeighborsClassifier(n_jobs = -1)\n",
    "                param_grid = param_grid\n",
    "                pg = ParameterGrid(param_grid)\n",
    "                train_scores = np.zeros(len(pg))\n",
    "                val_scores = np.zeros(len(pg))\n",
    "                models = []\n",
    "                \n",
    "                for p in range(len(pg)):\n",
    "                    params = pg[p]\n",
    "                    #print('   ', params)\n",
    "                    ML_algo.set_params(**params)\n",
    "                    ML_algo.fit(sub_X_train, sub_y_train_array)\n",
    "                    models.append(ML_algo) # save the model\n",
    "                    sub_y_train_pred = ML_algo.predict(sub_X_train)\n",
    "                    train_scores[p] = accuracy_score(sub_y_train_array, sub_y_train_pred)\n",
    "                    sub_y_val_pred = ML_algo.predict(sub_X_val)\n",
    "                    val_scores[p] = accuracy_score(sub_y_val_array, sub_y_val_pred)\n",
    "                    #print('   ', train_scores[p], val_scores[p])\n",
    "                best_params = np.array(pg)[val_scores == np.max(val_scores)]\n",
    "                #print('Best model parameters:\\n', best_params)\n",
    "                #print('Corresponding validation score:', np.max(val_scores))\n",
    "               \n",
    "                # plot train_scores and val_scores\n",
    "                # param_grid is ok\n",
    "                plt.figure(figsize = (5, 3))\n",
    "                plt.plot(train_scores, label = 'Training Accuracy')\n",
    "                plt.plot(val_scores, label = 'Validation Accuracy')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                \n",
    "                ML_algo.set_params(**best_params[0])\n",
    "                ML_algo.fit(sub_X_train, sub_y_train_array)\n",
    "                sub_y_test_pred = ML_algo.predict(sub_X_test)\n",
    "                sub_y_test_pred = pd.DataFrame(sub_y_test_pred, index = sub_y_test.index, \n",
    "                                               columns = ['sub_y_test_pred']) # convert into data frame\n",
    "                all_y_test_pred = pd.concat([all_y_test_pred, sub_y_test_pred])\n",
    "                    \n",
    "            all_y_test_pred = all_y_test_pred.sort_index()\n",
    "            y_test = y_test.sort_index()\n",
    "\n",
    "            # test accuracy in one-fold\n",
    "            # have n_splits scores for each random_state\n",
    "            accuracy_test = accuracy_score(all_y_test_pred, y_test) # total accuracy\n",
    "            accuracy_scores_test.append(accuracy_test)\n",
    "        # mean test accuracy for this random_state\n",
    "        mean_accuracy = np.mean(accuracy_scores_test)\n",
    "        mean_accuracy_scores.append(mean_accuracy)\n",
    "        accuracy_scores_random_state[random_state] = mean_accuracy\n",
    "        #print(f'Mean test accuracy for random state {random_state}: {mean_accuracy}\\n')\n",
    "    # mean & std accuracy for all random states\n",
    "    overall_mean_accuracy = np.mean(mean_accuracy_scores)\n",
    "    overall_std_accuracy = np.std(mean_accuracy_scores)\n",
    "    #print(f'Overall mean test accuracy across all random states: {overall_mean_accuracy}')\n",
    "    #print(f'Overall std test accuracy across all random states: {overall_std_accuracy}\\n')\n",
    "    \n",
    "    return overall_mean_accuracy, overall_std_accuracy, accuracy_scores_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c0ded-c784-4f55-9c3e-fda7ab772b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [42, 123]\n",
    "param_grid = {\n",
    "    'max_depth': [1, 3, 9, 12, None],\n",
    "    'max_features': [0.5, 0.75, 1, None]\n",
    "}\n",
    "\n",
    "mean_accuracy_knn, std_accuracy_knn, accuracy_random_state_knn = MLpipe_kfold_reduced_features_knn(X, y, random_states, \n",
    "                                                                                                   preprocessor, param_grid, \n",
    "                                                                                                   n_splits = 3)\n",
    "print('KNN mean accuracy:', mean_accuracy_knn)\n",
    "print('KNN std accuracy:', std_accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb5342-53f9-4b2a-b2f3-1579320d47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_test.isnull()\n",
    "len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b0124-1ba2-4f7f-9276-e4ef9a7ca8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.unique(mask, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7bf1e-77ec-4a77-b9b2-616814a38ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e9bfc-61e1-4117-858a-f6dfd056a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pdays = X.drop(columns = ['pdays'])\n",
    "X_pdays.isnull().sum(axis = 0)\n",
    "len(X_pdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7e07d-25b2-4567-a5d6-80d9a06bde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = X[['num__LotFrontage','num__MasVnrArea','num__GarageYrBlt']].isnull()\n",
    "\n",
    "unique_rows, counts = np.unique(mask, axis=0,return_counts=True)\n",
    "print(unique_rows.shape) # 6 patterns, we will train 6 models (one model for each pattern)\n",
    "for i in range(len(counts)):\n",
    "    print(unique_rows[i],counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20ccc2-0d2b-4153-adfd-2a17eb0424cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2101a1eb-beba-4e43-8023-c52107156c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sub_y_train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914fd5c-ee24-4c45-9407-7bdf72b87e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sub_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9121040b-59a2-41d9-98ff-e6ab9a4cf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_y_train = pd.DataFrame(data = sub_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b88ea2-42b3-4bca-8ab8-7e8da238ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(sub_X_train, sub_y_train_mod)\n",
    "sub_y_val_pre = clf.predict(sub_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde340ce-7034-4959-9357-bcad0c58f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(np.array(y_train), (1, -1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b6328-1dee-471b-bb99-5be073660670",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_test.isnull()\n",
    "unique_rows, counts = np.unique(mask, axis=0,return_counts=True)\n",
    "print(unique_rows.shape) # 2 patterns, we will train 2 models (one model for each pattern)\n",
    "for i in range(len(counts)):\n",
    "    print(unique_rows[i],counts[i])\n",
    "unique_rows[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c877c-8c38-4016-a0ea-6d764a5d1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_X_train = df_train[df_train.columns[~unique_rows[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911e83e-00bd-45e1-a76f-3a7a9f5e61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_X_train = pd.DataFrame()\n",
    "df_train[df_train.columns[~unique_rows[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1bafc-be1b-40b7-9fff-d4be056f7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_X_test[X_test.columns[~unique_rows[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed273bd-a976-4156-af1a-0513609af4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns[~unique_rows[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bb190-4e82-4a4a-ace0-c20b499e63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_X_test = pd.DataFrame()\n",
    "sub_X_test = pd.concat([sub_X_test, df_test.iloc[[1]]])\n",
    "sub_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad8480-7366-49aa-917c-fe7e4cd1ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "xgb_model(X_train = df_train, Y_train = y_train, X_CV = df_val, y_CV = y_val, X_test = df_test, y_test = y_test,\n",
    "          verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b67356-419a-4143-b31d-4a7df5079651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(X_train, Y_train, X_CV, y_CV, X_test, y_test, verbose=1):\n",
    "\n",
    "    # make into row vectors to avoid an obnoxious sklearn/xgb warning\n",
    "    Y_train = np.reshape(np.array(Y_train), (1, -1)).ravel()\n",
    "    y_CV = np.reshape(np.array(y_CV), (1, -1)).ravel()\n",
    "    y_test = np.reshape(np.array(y_test), (1, -1)).ravel()\n",
    "\n",
    "    XGB = xgboost.XGBRegressor(n_jobs=1)\n",
    "    \n",
    "    # find the best parameter set\n",
    "    # can change the grid if you want\n",
    "    param_grid = {\"learning_rate\": [0.03],\n",
    "                  \"n_estimators\": [10000],\n",
    "                  \"seed\": [0],\n",
    "                  #\"reg_alpha\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  #\"reg_lambda\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  \"missing\": [np.nan], \n",
    "                  #\"max_depth\": [1,3,10,30,100,],\n",
    "                  \"colsample_bytree\": [0.9],              \n",
    "                  \"subsample\": [0.66]}\n",
    "\n",
    "    pg = ParameterGrid(param_grid)\n",
    "\n",
    "    scores = np.zeros(len(pg))\n",
    "\n",
    "    for i in range(len(pg)):\n",
    "        if verbose >= 5:\n",
    "            print(\"Param set \" + str(i + 1) + \" / \" + str(len(pg)))\n",
    "        params = pg[i]\n",
    "        XGB.set_params(**params)\n",
    "        eval_set = [(X_CV, y_CV)]\n",
    "        XGB.fit(X_train, Y_train,\n",
    "                early_stopping_rounds=50, eval_set=eval_set, verbose=False)# with early stopping\n",
    "        y_CV_pred = XGB.predict(X_CV, ntree_limit=XGB.best_ntree_limit)\n",
    "        scores[i] = mean_squared_error(y_CV,y_CV_pred)\n",
    "    # what are the best hyper-parameter combinations based on the CV pipeline\n",
    "    best_params = np.array(pg)[scores == np.max(scores)]\n",
    "    if verbose >= 4:\n",
    "        print('Test set max score and best parameters are:')\n",
    "        print(np.max(scores))\n",
    "        print(best_params)\n",
    "\n",
    "    # test the model on the test set with the best parameter set\n",
    "    XGB.set_params(**best_params[0])\n",
    "    XGB.fit(X_train,Y_train,\n",
    "            early_stopping_rounds=50,eval_set=eval_set, verbose=False)\n",
    "    y_test_pred = XGB.predict(X_test, ntree_limit=XGB.best_ntree_limit)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print ('The MSE is:',mean_squared_error(y_test,y_test_pred))\n",
    "    if verbose >= 2:\n",
    "        print ('The predictions are:')\n",
    "        print (y_test_pred)\n",
    "    if verbose >= 3:\n",
    "        print(\"Feature importances:\")\n",
    "        print(XGB.feature_importances_)\n",
    "\n",
    "    return (mean_squared_error(y_test,y_test_pred), y_test_pred, XGB.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2015f2-b6bb-4969-9dfd-a434932e34b5",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729b3a1-622d-44b4-80f3-f7e54d7c2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def MLpipe_XGBoost(X, y, preprocessor, random_states):\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    best_models = []\n",
    "    test_sets = [] # save each random state's test set into a list\n",
    "\n",
    "    for random_state in random_states:\n",
    "        X_train, X_other, y_train, y_other = train_test_split(X, y, train_size = 0.6,\n",
    "                                                              random_state = 42 * random_state)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size = 0.5,\n",
    "                                                        random_state = 42 * random_state)\n",
    "        # preprocessing\n",
    "        df_train = pd.DataFrame(data = preprocessor.fit_transform(X_train), \n",
    "                                columns = preprocessor.get_feature_names_out())\n",
    "        df_val = pd.DataFrame(data = preprocessor.transform(X_val), \n",
    "                              columns = preprocessor.get_feature_names_out())\n",
    "        df_test = pd.DataFrame(data = preprocessor.transform(X_test), \n",
    "                               columns = preprocessor.get_feature_names_out())\n",
    "\n",
    "        # save each random state's test set into a list\n",
    "        # save both the feature matrix and the target series\n",
    "        df_y = pd.DataFrame(data = y_test, columns = ['y']).reset_index(drop = True)\n",
    "        df_test1 = df_test.reset_index(drop = True)\n",
    "        df_combined = pd.concat([df_test1, df_y], axis = 1)\n",
    "        test_sets.append(df_combined)\n",
    "        \n",
    "        param_grid = {\n",
    "            'max_depth': [1, 3, 10, 30, 100],\n",
    "            'learning_rate': [0.33],\n",
    "            'n_estimators': [10000],\n",
    "            'seed': [0],\n",
    "            'reg_alpha': [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "            'subsample': [0.66],\n",
    "            'colsample_bytree': [0.9]\n",
    "        }\n",
    "       \n",
    "        best_ap_score = 0\n",
    "        best_model = None\n",
    "        best_params = None\n",
    "\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            clf = XGBClassifier(random_state = 42 * random_state)\n",
    "            clf.set_params(**params, early_stopping_rounds = 50)\n",
    "            clf.fit(df_train, y_train, eval_set = [(df_val, y_val)], \n",
    "                    verbose = False)\n",
    "            y_val_pred_prob = clf.predict_proba(df_val)[:, 1]\n",
    "            ap_score = average_precision_score(y_val, y_val_pred_prob)\n",
    "            if ap_score > best_ap_score:\n",
    "                best_ap_score = ap_score\n",
    "                best_model = clf\n",
    "                best_params = params\n",
    "       \n",
    "        best_models.append(best_model)\n",
    "        train_score = average_precision_score(y_train, best_model.predict_proba(df_train)[:, 1])\n",
    "        test_score = average_precision_score(y_test, best_model.predict_proba(df_test)[:, 1])\n",
    "        test_scores.append(test_score)\n",
    "        train_scores.append(train_score)\n",
    "                            \n",
    "    print(f'Mean of test scores: {np.mean(test_scores)}')\n",
    "    print(f'Standard deviation of test scores: {np.std(test_scores)}')\n",
    "    return best_models, test_scores, test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c9c30-20ba-409e-ace4-7400f93a1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [42, 123, 456, 789, 101]\n",
    "best_models, test_scores, test_sets = MLpipe_XGBoost(X, y, preprocessor, random_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3ddfe-3c29-49c3-945d-a067d37e132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'gain'\n",
    "a = best_models[2].get_booster().get_score(importance_type = f)\n",
    "sorted_a = sorted(a.items(), key = lambda x: x[1], reverse = True)\n",
    "sorted_dict = dict(sorted_a)\n",
    "sorted_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
